{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "from math import log, exp\n",
    "from array import array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(fname_img, fname_lbl, n):\n",
    "    f = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", f.read(8))\n",
    "    lbl = array(\"b\", f.read())\n",
    "    f.close()\n",
    "\n",
    "    f = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "    img = array(\"B\", f.read())\n",
    "    f.close()\n",
    "\n",
    "    tmp = [1]\n",
    "    img_matrix = []\n",
    "    for x in img.tolist():\n",
    "        tmp.append(x)\n",
    "        if len(tmp) == 785:\n",
    "            img_matrix.append(tmp)\n",
    "            tmp = [1]\n",
    "            if (len(img_matrix) == n):\n",
    "                break\n",
    "\n",
    "    return lbl.tolist()[:n], img_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "test_size = 20000\n",
    "\n",
    "train_lbl, train_img = read(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\", train_size)\n",
    "test_lbl, test_img = read(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "print len(train_lbl), len(train_img)\n",
    "print len(test_lbl), len(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(result, lbl):\n",
    "    correct = sum([int(result[i] == lbl[i]) for i in range(len(result))])\n",
    "    return float(correct)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9691\n",
      "[[ 973    0    7    0    0    1    4    0    6    2]\n",
      " [   1 1129    6    1    7    1    2   14    1    5]\n",
      " [   1    3  992    2    0    0    0    6    3    1]\n",
      " [   0    0    5  970    0   12    0    2   14    6]\n",
      " [   0    1    1    1  944    2    3    4    5   10]\n",
      " [   1    1    0   19    0  860    5    0   13    5]\n",
      " [   3    1    2    0    3    5  944    0    3    1]\n",
      " [   1    0   16    7    5    1    0  992    4   11]\n",
      " [   0    0    3    7    1    6    0    0  920    1]\n",
      " [   0    0    0    3   22    4    0   10    5  967]]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=1, p=2, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1, weights='distance', p=2) #euclidean_distance\n",
    "clf.fit(train_img, train_lbl)\n",
    "result = clf.predict(test_img)\n",
    "print \"Accuracy: \", cal_accuracy(result, test_lbl)\n",
    "print confusion_matrix(result, test_lbl)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8864\n",
      "[[ 940    0   10   14    4   15   20    2   10    9]\n",
      " [   0 1092   11    5    0    4    4    0   17    2]\n",
      " [   3    5  881   27    4    4    9   31    8    3]\n",
      " [   2    0   28  867    3   48    1    4   35   15]\n",
      " [   1    1    8    1  890   10    9   11   19   51]\n",
      " [   2    0    5   33    1  732   11    4   69    6]\n",
      " [   4    3   16    5   14   23  891    1   11    0]\n",
      " [   2    2    9   15    1    7    0  915   10   29]\n",
      " [  24   28   60   24    9   35   11    8  774   12]\n",
      " [   2    4    4   19   56   14    2   52   21  882]]\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(train_img, train_lbl)\n",
    "result = clf.predict(test_img)\n",
    "print \"Accuracy: \", cal_accuracy(result, test_lbl)\n",
    "print confusion_matrix(result, test_lbl)\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "0 476.446 93038.4\n",
      "100 26.423 5419.06\n",
      "200 9.20221 3308.02\n",
      "300 18.8577 2652.8\n",
      "400 4.57763 2158.62\n",
      "500 10.012 1937.14\n",
      "600 3.25086 1692.13\n",
      "700 8.40919 1674.04\n",
      "800 10.2694 1437.58\n",
      "900 3.13665 1339.29\n",
      "1000 4.68208 1215.47\n",
      "1100 7.04251 1311.1\n",
      "1200 2.18923 1104.09\n",
      "1300 3.83214 1079.4\n",
      "1400 2.25226 1033.69\n",
      "1500 4.7279 973.35\n",
      "1600 6.22996 1006.83\n",
      "1700 11.3094 913.99\n",
      "1800 2.32752 831.35\n",
      "1900 3.07252 855.03\n",
      "2000 1.97749 750.29\n",
      "2100 2.97205 776.746\n",
      "2200 0.850536 705.181\n",
      "2300 8.21532 677.642\n",
      "2400 9.98067 694.923\n",
      "2500 1.31076 617.001\n",
      "2600 5.28489 612.196\n",
      "2700 1.15122 585.954\n",
      "2800 0.659887 608.897\n",
      "2900 3.23978 618.086\n",
      "3000 2.65204 561.061\n",
      "3100 4.41707 591.88\n",
      "3200 6.09455 560.737\n",
      "3300 5.15061 504.121\n",
      "3400 2.60841 529.401\n",
      "3500 0.554721 545.522\n",
      "3600 1.52265 498.287\n",
      "3700 3.4357 524.351\n",
      "3800 2.97775 444.636\n",
      "3900 0.485911 443.213\n",
      "4000 0.884766 453.117\n",
      "4100 4.75405 415.424\n",
      "4200 0.941422 463.697\n",
      "4300 3.55434 420.567\n",
      "4400 2.85585 421.03\n",
      "4500 0.35793 426.151\n",
      "4600 0.3569 388.868\n",
      "4700 0.90236 418.475\n",
      "4800 5.55428 387.187\n",
      "4900 0.103067 441.483\n",
      "5000 0.272016 354.81\n",
      "5100 3.38824 380.521\n",
      "5200 0.308627 365.338\n",
      "5300 0.836936 402.696\n",
      "5400 0.69959 370.654\n",
      "5500 1.53931 333.959\n",
      "5600 1.04338 374.825\n",
      "5700 0.261172 406.108\n",
      "5800 1.28776 352.879\n",
      "5900 2.76559 345.449\n",
      "6000 2.57293 376.265\n",
      "6100 0.610913 361.013\n",
      "6200 5.27717 351.701\n",
      "6300 1.35018 378.669\n",
      "6400 0.220416 341.105\n",
      "6500 0.536507 336.487\n",
      "6600 0.157162 325.6\n",
      "6700 0.218225 321.471\n",
      "6800 0.303602 330.187\n",
      "6900 0.0434022 312.312\n",
      "7000 0.560583 322.411\n",
      "7100 1.15206 286.363\n",
      "7200 0.477313 312.299\n",
      "7300 0.254717 304.89\n",
      "7400 0.398232 328.362\n",
      "7500 0.692736 301.844\n",
      "7600 1.2812 283.186\n",
      "7700 0.130363 268.337\n",
      "7800 0.0369033 287.881\n",
      "7900 0.567515 295.294\n",
      "8000 0.059751 337.751\n",
      "8100 1.66064 291.911\n",
      "8200 0.394496 269.594\n",
      "8300 0.182011 279.139\n",
      "8400 0.74066 266.448\n",
      "8500 0.737712 334.952\n",
      "8600 6.27228 278.496\n",
      "8700 4.35376 308.818\n",
      "8800 1.98501 270.754\n",
      "8900 0.222426 291.877\n",
      "9000 0.856062 268.021\n",
      "9100 0.13422 304.617\n",
      "9200 0.0367233 273.508\n",
      "9300 1.42094 268.915\n",
      "9400 0.0826301 265.422\n",
      "9500 3.05895 249.224\n",
      "9600 1.1828 257.493\n",
      "9700 4.12496 253.127\n",
      "9800 0.3684 266.91\n",
      "9900 0.0553885 289.368\n",
      "10000 0.0885354 279.351\n",
      "10100 0.12978 272.011\n",
      "10200 0.0408129 250.207\n",
      "10300 1.84896 270.14\n",
      "10400 0.91286 273.584\n",
      "10500 0.165693 265.691\n",
      "10600 0.320421 267.78\n",
      "10700 1.14841 267.708\n",
      "10800 0.106899 323.855\n",
      "10900 0.0662685 249.572\n",
      "11000 0.0798153 253.355\n",
      "11100 0.0328727 253.282\n",
      "11200 0.0764064 264.423\n",
      "11300 0.700877 241.989\n",
      "11400 0.159076 258.44\n",
      "11500 0.0276748 252.832\n",
      "11600 0.103275 239.72\n",
      "11700 0.450724 261.966\n",
      "11800 0.13277 261.547\n",
      "11900 0.089283 235.646\n",
      "12000 0.401416 234.919\n",
      "12100 0.0819588 231.98\n",
      "12200 0.0758192 258.557\n",
      "12300 0.0750529 230.255\n",
      "12400 0.272227 232.844\n",
      "12500 0.0622413 256.529\n",
      "12600 0.09511 290.036\n",
      "12700 0.0275715 229.288\n",
      "12800 0.476683 242.081\n",
      "12900 0.294871 238.167\n",
      "13000 0.398602 246.416\n",
      "13100 0.586831 239.664\n",
      "13200 0.0241132 248.42\n",
      "13300 0.14162 237.25\n",
      "13400 0.193481 241.101\n",
      "13500 0.0173038 245.987\n",
      "13600 0.668502 238.051\n",
      "13700 0.00928182 258.602\n",
      "13800 0.0256211 251.221\n",
      "13900 0.0215447 215.743\n",
      "14000 0.0382726 214.733\n",
      "14100 1.53521 260.403\n",
      "14200 0.0979382 247.531\n",
      "14300 0.0237826 218.468\n",
      "14400 1.61807 226.936\n",
      "14500 1.15219 234.933\n",
      "14600 0.934527 255.477\n",
      "14700 0.0128344 260.147\n",
      "14800 0.0304296 231.074\n",
      "14900 1.32328 269.035\n",
      "15000 0.0270151 227.327\n",
      "15100 0.220287 257.142\n",
      "15200 0.173632 216.625\n",
      "15300 0.553942 229.418\n",
      "15400 0.0106278 213.659\n",
      "15500 0.0374237 223.993\n",
      "15600 0.487097 234.518\n",
      "15700 0.523571 227.364\n",
      "15800 0.0159241 227.668\n",
      "15900 0.0743455 274.045\n",
      "16000 0.242114 233.106\n",
      "16100 0.354308 224.2\n",
      "16200 0.124913 256.852\n",
      "16300 0.0429694 221.539\n",
      "16400 0.0230995 237.501\n",
      "16500 0.0860976 205.343\n",
      "16600 0.0234916 216.574\n",
      "16700 0.101454 224.198\n",
      "16800 0.00850414 245.101\n",
      "16900 0.059719 244.177\n",
      "17000 0.131815 214.568\n",
      "17100 0.127786 230.878\n",
      "17200 0.0115568 226.792\n",
      "17300 0.12893 221.248\n",
      "17400 0.0981816 230.106\n",
      "17500 0.0561075 230.704\n",
      "17600 0.10654 227.07\n",
      "17700 0.149953 222.528\n",
      "17800 0.00955219 231.249\n",
      "17900 0.0810025 231.305\n",
      "18000 0.196992 231.863\n",
      "18100 0.00250935 217.273\n",
      "18200 0.373445 222.617\n",
      "18300 0.389884 265.192\n",
      "18400 0.0011702 212.557\n",
      "18500 0.0144478 222.238\n",
      "18600 0.0107746 237.944\n",
      "18700 0.0389869 203.986\n",
      "18800 0.081811 207.281\n",
      "18900 0.0425018 227.372\n",
      "19000 0.00188674 240.375\n",
      "19100 0.00939183 232.767\n",
      "19200 0.317244 229.364\n",
      "19300 0.0787112 234.717\n",
      "19400 0.118866 231.202\n",
      "19500 0.255164 245.963\n",
      "19600 0.135557 278.095\n",
      "19700 0.199937 214.566\n",
      "19800 0.124578 231.072\n",
      "19900 0.0163496 228.216\n",
      "0.9941\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "print \n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "result = open('result.txt', 'wb')\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    if i % 100 == 0:\n",
    "        train_loss = cross_entropy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        test_loss = cross_entropy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "        result.write(str(i + 1) + ' ' + str(train_loss) + ' ' + str(test_loss) + '\\n')\n",
    "        print i, train_loss, test_loss\n",
    "\n",
    "result.close()\n",
    "test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "print test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
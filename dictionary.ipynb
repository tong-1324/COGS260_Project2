{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "import random\n",
    "import struct\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read(fname_img, fname_lbl):\n",
    "    f = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", f.read(8))\n",
    "    lbl = array(\"b\", f.read())\n",
    "    f.close()\n",
    "\n",
    "    f = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "    img = array(\"B\", f.read())\n",
    "    f.close()\n",
    "\n",
    "    tmp = []\n",
    "    cur_img = []\n",
    "    img_matrix = []\n",
    "    for x in img.tolist():\n",
    "        tmp.append(x)\n",
    "        if len(tmp) == 28:\n",
    "            cur_img.append(tmp)\n",
    "            tmp = []\n",
    "        if len(cur_img) == 28:\n",
    "            img_matrix.append(cur_img)\n",
    "            cur_img = []\n",
    "\n",
    "    return lbl.tolist(), img_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "\n",
    "train_lbl, train_img = read(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\")\n",
    "test_lbl, test_img = read(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\")\n",
    "\n",
    "index_shuf = range(train_size)\n",
    "random.shuffle(index_shuf)\n",
    "x = []\n",
    "y = []\n",
    "for i in range(train_size):\n",
    "    x.append(train_img[index_shuf[i]])\n",
    "    y.append(train_lbl[index_shuf[i]])\n",
    "train_lbl, train_img = y, x\n",
    "\n",
    "train_img = np.uint8(np.array(train_img))\n",
    "test_img = np.uint8(np.array(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_sift(in_img):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(in_img, None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sift_sample(imgs, train_lbl, sample_num):\n",
    "    descriptors = np.array([])\n",
    "    samples = [0] * 10\n",
    "    \n",
    "    cur = 0\n",
    "    while (sum(samples) < sample_num):\n",
    "        if (samples[train_lbl[cur]] >= (sample_num/10)):\n",
    "            cur += 1\n",
    "            continue\n",
    "        samples[train_lbl[cur]] += 1\n",
    "        \n",
    "        kp, des = cal_sift(np.array(imgs[cur]))\n",
    "        if (des is None):\n",
    "            cur += 1\n",
    "            continue\n",
    "        if len(descriptors):\n",
    "            descriptors = np.append(descriptors, des, axis=0)\n",
    "        else:\n",
    "            descriptors = des\n",
    "        cur += 1\n",
    "        \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79081, 128)\n"
     ]
    }
   ],
   "source": [
    "cluster_num = 200\n",
    "sample_num = 10000\n",
    "iter_num = 300\n",
    "\n",
    "descriptors = sift_sample(train_img, train_lbl, sample_num)\n",
    "print descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriptor_cluster(descriptors, cluster_num, iter_nume):\n",
    "    cluster = KMeans(n_clusters=cluster_num, max_iter=iter_num).fit(descriptors)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster = descriptor_cluster(descriptors, cluster_num, iter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_feature(img, cluster, cluster_num):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    feature_layer1 = [0.0] * cluster_num\n",
    "    feature_layer2 = [0.0] * cluster_num * 4\n",
    "    feature_layer3 = [0.0] * cluster_num * 16\n",
    "    \n",
    "    kp, des = cal_sift(img)\n",
    "    if (des is not None):\n",
    "        cluster_result = cluster.predict(des)\n",
    "        for c in cluster_result:\n",
    "            feature_layer1[c] += 0.5\n",
    "            \n",
    "    cur = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            cur += 1\n",
    "            crop_img = img[i*14 : (i+1)*14 -1, j*14 : (j+1)*14 -1]\n",
    "            kp, des = cal_sift(crop_img)\n",
    "            if (des is not None):\n",
    "                cluster_result = cluster.predict(des)\n",
    "                for c in cluster_result:\n",
    "                    feature_layer2[(cur-1)*cluster_num + c] += 0.25\n",
    "                    \n",
    "    cur = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            cur += 1\n",
    "            crop_img = img[i*7 : (i+1)*7 -1, j*7 : (j+1)*7 -1]\n",
    "            kp, des = cal_sift(crop_img)\n",
    "            if (des is not None):\n",
    "                cluster_result = cluster.predict(des)\n",
    "                for c in cluster_result:\n",
    "                    feature_layer3[(cur-1)*cluster_num + c] += 0.25\n",
    "    \n",
    "    feature = feature_layer1 + feature_layer2 + feature_layer3\n",
    "    return np.array(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_features(imgs, cluster, cluster_num):\n",
    "    features = []\n",
    "    for img in imgs:\n",
    "        f = img_to_feature(img, cluster, cluster_num)\n",
    "        features.append(f)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train = generate_features(train_img, cluster, cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_test = generate_features(test_img, cluster, cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test(features_train, features_test, lbl_train, lbl_test):    \n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(features_train, lbl_train)\n",
    "    result = clf.predict(features_test)\n",
    "    error = sum([int(result[i] != test_lbl[i]) for i in range(len(result))])\n",
    "    print \"Accuracy: \", 1 - float(error)/len(result)\n",
    "    print confusion_matrix(result, test_lbl)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8661\n",
      "[[ 920    0   28    3    3   34   43   11   12   12]\n",
      " [   7 1120   28    9   18   21   20   69    2   13]\n",
      " [   6    4  850   21   21   10   13   44   18    7]\n",
      " [   2    1   13  881    4   23    7    8   18   11]\n",
      " [   2    1   10   10  864    8    9   18   12   20]\n",
      " [   9    1    8   43    7  714   27    4   12   19]\n",
      " [  16    1   13   12   11   40  761   11   12   42]\n",
      " [   8    6   58   18   11   12   20  843    9   11]\n",
      " [   7    1   15   11   13   10    8    2  855   21]\n",
      " [   3    0    9    2   30   20   50   18   24  853]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test(features_train, features_test, train_lbl, test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
